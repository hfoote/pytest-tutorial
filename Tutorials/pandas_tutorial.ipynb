{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be4adee5",
   "metadata": {},
   "source": [
    "# A Crash-Course on Pandas\n",
    "\n",
    "A 30-minute intro to the main functionality of the `pandas` package. Please also see the [official pandas tutorials](https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html) on which this notebook is heavily based. I also recommend the [\"10 minutes to pandas\"](https://pandas.pydata.org/docs/user_guide/10min.html) crash-course on the [offical docs website](https://pandas.pydata.org/docs/index.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f798bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec206ebf",
   "metadata": {},
   "source": [
    "Pandas is a package for manipulating data. I like to think of pandas as Python's version of a spreadsheet. There are two main types of data structures in pandas, Series (1-D; a single column), and DataFrame (2-D; a table), which is similar to (but more powerful than) a data.frame in R. DataFrames are capable of everything a spreadsheet is, and are also capable of handling relational data similar to SQL-based relational databases.\n",
    "\n",
    "Let's look at both in turn:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dedf4a",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "A Series is a labeled 1-D dataset. They can be instantiated manually, or extracted from a DataFrame. To build one manually,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a594a52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    87\n",
      "1    91\n",
      "2    98\n",
      "3    85\n",
      "4    90\n",
      "Name: test scores, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ex_series = pd.Series([87, 91, 98, 85, 90], name=\"test scores\")\n",
    "print(ex_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ce597",
   "metadata": {},
   "source": [
    "Note that the data is automatically labeled with an integer index. We can specify our own index, say a 4-digit student ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c6c264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001    87\n",
      "0002    91\n",
      "0003    98\n",
      "0004    85\n",
      "0005    90\n",
      "Name: test scores, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_scores = pd.Series(\n",
    "\t[87, 91, 98, 85, 90], \n",
    "\tname=\"test scores\", \n",
    "\tindex=[\"0001\", \"0002\", \"0003\", \"0004\", \"0005\"]\n",
    ")\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde36a0c",
   "metadata": {},
   "source": [
    "Data are accessed using their index, NOT their position in the series. Note that you *can* technically access custom-indexed data by its position, but pandas will give you a warning. The correct way to access data by position is to use the iloc method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072538c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "98\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "print(ex_series[1])\n",
    "print(test_scores[\"0003\"])\n",
    "print(test_scores.iloc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3249a34",
   "metadata": {},
   "source": [
    "Series can also be turned into numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cda671c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87 91 98 85 90]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "scores_array = test_scores.to_numpy()\n",
    "print(scores_array)\n",
    "print(type(scores_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca60e60c",
   "metadata": {},
   "source": [
    "## Data Frames\n",
    "\n",
    "A DataFrame is a 2-D labeled dataset organized into a table with rows and columns. We can also make these manually using dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f96a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Student ID  Age  Score\n",
      "0       0001   13     87\n",
      "1       0002   14     91\n",
      "2       0003   14     98\n",
      "3       0004   13     85\n",
      "4       0005   13     90\n"
     ]
    }
   ],
   "source": [
    "data_dict = {\n",
    "\t\"Student ID\": [\"0001\", \"0002\", \"0003\", \"0004\", \"0005\"],\n",
    "\t\"Age\": [13, 14, 14, 13, 13],\n",
    "\t\"Score\": [87, 91, 98, 85, 90]\n",
    "}\n",
    "ex_df = pd.DataFrame(data_dict)\n",
    "print(ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dfaf94",
   "metadata": {},
   "source": [
    "To select a column, use its name like accessing a dict. Note that columns of a DataFrame are Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327f0c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    13\n",
      "1    14\n",
      "2    14\n",
      "3    13\n",
      "4    13\n",
      "Name: Age, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "  Student ID  Age\n",
      "0       0001   13\n",
      "1       0002   14\n",
      "2       0003   14\n",
      "3       0004   13\n",
      "4       0005   13\n"
     ]
    }
   ],
   "source": [
    "print(ex_df[\"Age\"])\n",
    "print(type(ex_df[\"Age\"]))\n",
    "\n",
    "# you can also select more than one column with a list:\n",
    "print(ex_df[[\"Student ID\",\"Age\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b5ecd",
   "metadata": {},
   "source": [
    "To select (a) row(s), you have a few options. I think the easiest is to use a boolean array. This is the operation that you're wrapping in ParaFrame's filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a55d8966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Student ID  Age  Score\n",
      "0       0001   13     87\n",
      "  Student ID  Age  Score\n",
      "1       0002   14     91\n",
      "2       0003   14     98\n",
      "4       0005   13     90\n"
     ]
    }
   ],
   "source": [
    "print(ex_df[ex_df[\"Student ID\"] == \"0001\"])\n",
    "print(ex_df[ex_df[\"Score\"] >= 90])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28072b5",
   "metadata": {},
   "source": [
    "Like Series, you can also use the loc and iloc methods to select rows by index and position, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec0384d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student ID    0005\n",
      "Age             13\n",
      "Score           90\n",
      "Name: Student 5, dtype: object\n",
      "Student ID    0001\n",
      "Age             13\n",
      "Score           87\n",
      "Name: Student 1, dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# let's add a manual index\n",
    "ex_df.index = [\"Student 1\", \"Student 2\", \"Student 3\", \"Student 4\", \"Student 5\"]\n",
    "\n",
    "print(ex_df.loc[\"Student 5\"])\n",
    "print(ex_df.iloc[0])\n",
    "\n",
    "# Note these return Series as well!\n",
    "print(type(ex_df.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ae3b8",
   "metadata": {},
   "source": [
    "## I/O\n",
    "\n",
    "In addition to manual creation, pandas can read and write dataframes to/from a variety of common file types, including csv, excel, hdf5, json, sql, and more! These operations are performed with the `DataFrame.read_*` and `DataFrame.to_*` methods. For more info, see the [docs](https://pandas.pydata.org/docs/user_guide/io.html). For example, to read a csv file, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d89a18e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                                Heikkinen, Miss Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                        Graham, Miss Margaret Edith  female  19.0      0   \n",
      "888            Johnston, Miss Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# let's grab the Titanic data file that pandas offers for its tutorials. \n",
    "import requests\n",
    "import io\n",
    "\n",
    "data_url = \"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv\"\n",
    "response = requests.get(data_url).content\n",
    "# Note that if you already have a file on-hand, you just pass the file location to read_csv()\n",
    "df = pd.read_csv(io.StringIO(response.decode('utf-8')))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5637fa9",
   "metadata": {},
   "source": [
    "Pandas auto-detects the data types of each column, but you can also specify them yourself with the `dtypes` kwarg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56eeb777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78750032",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "As we saw in Evan's last debugging example, missing or bad data propagates through calculations using dataframes. To deal with bad or missing data, pandas offers the dropna() method to drop rows with any missing data, and the fillna() method to replace missing data with a placeholder. For more info, see the [missing data guide](https://pandas.pydata.org/docs/user_guide/missing_data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b1af2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "(183, 12)\n",
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.dropna().shape)\n",
    "print(df.fillna(0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae0f49",
   "metadata": {},
   "source": [
    "## Creating new and derived columns\n",
    "Creating new columns is as easy as assigning an array or series of the proper dimension to an unused column name. This can also be used to create columns derived from existing ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0456b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                                Heikkinen, Miss Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                        Graham, Miss Margaret Edith  female  19.0      0   \n",
      "888            Johnston, Miss Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  Brought Cellphone  \n",
      "0        0         A/5 21171   7.2500   NaN        S                  0  \n",
      "1        0          PC 17599  71.2833   C85        C                  0  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S                  0  \n",
      "3        0            113803  53.1000  C123        S                  0  \n",
      "4        0            373450   8.0500   NaN        S                  0  \n",
      "..     ...               ...      ...   ...      ...                ...  \n",
      "886      0            211536  13.0000   NaN        S                  0  \n",
      "887      0            112053  30.0000   B42        S                  0  \n",
      "888      2        W./C. 6607  23.4500   NaN        S                  0  \n",
      "889      0            111369  30.0000  C148        C                  0  \n",
      "890      0            370376   7.7500   NaN        Q                  0  \n",
      "\n",
      "[891 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# add a column manually\n",
    "df[\"Brought Cellphone\"] = np.zeros(df.shape[0], dtype=int)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c54f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                                Heikkinen, Miss Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                        Graham, Miss Margaret Edith  female  19.0      0   \n",
      "888            Johnston, Miss Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  Brought Cellphone  \\\n",
      "0        0         A/5 21171   7.2500   NaN        S                  0   \n",
      "1        0          PC 17599  71.2833   C85        C                  0   \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S                  0   \n",
      "3        0            113803  53.1000  C123        S                  0   \n",
      "4        0            373450   8.0500   NaN        S                  0   \n",
      "..     ...               ...      ...   ...      ...                ...   \n",
      "886      0            211536  13.0000   NaN        S                  0   \n",
      "887      0            112053  30.0000   B42        S                  0   \n",
      "888      2        W./C. 6607  23.4500   NaN        S                  0   \n",
      "889      0            111369  30.0000  C148        C                  0   \n",
      "890      0            370376   7.7500   NaN        Q                  0   \n",
      "\n",
      "     Fare Tax  \n",
      "0    0.580000  \n",
      "1    5.702664  \n",
      "2    0.634000  \n",
      "3    4.248000  \n",
      "4    0.644000  \n",
      "..        ...  \n",
      "886  1.040000  \n",
      "887  2.400000  \n",
      "888  1.876000  \n",
      "889  2.400000  \n",
      "890  0.620000  \n",
      "\n",
      "[891 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# add a derived column\n",
    "df[\"Fare Tax\"] = 0.08 * df[\"Fare\"]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bd2a55",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "Pandas has some built-in functionality for calulating summary stats for columns. Of course, it's always possible to extract a column to an array (as shown previously) and perform whataver fancy operations you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84562ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    714.000000\n",
       "mean      29.699118\n",
       "std       14.526497\n",
       "min        0.420000\n",
       "25%       20.125000\n",
       "50%       28.000000\n",
       "75%       38.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eveything at once\n",
    "df[\"Age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cc1132c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.69911764705882\n",
      "14.526497332334042\n"
     ]
    }
   ],
   "source": [
    "# or just one at a time\n",
    "print(df[\"Age\"].mean())\n",
    "print(df[\"Age\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c09a73",
   "metadata": {},
   "source": [
    "## Joining, Merging, and Concatenation\n",
    "Pandas also offers a few different methods for combining multiple tables. I think the [documentation](https://pandas.pydata.org/docs/user_guide/merging.html) has some good examples, so I'm replicating some of these here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b28ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "4  A4  B4  C4  D4\n",
      "5  A5  B5  C5  D5\n",
      "6  A6  B6  C6  D6\n",
      "7  A7  B7  C7  D7\n",
      "     A    B    C    D    A    B    C    D\n",
      "0   A0   B0   C0   D0  NaN  NaN  NaN  NaN\n",
      "1   A1   B1   C1   D1  NaN  NaN  NaN  NaN\n",
      "2   A2   B2   C2   D2  NaN  NaN  NaN  NaN\n",
      "3   A3   B3   C3   D3  NaN  NaN  NaN  NaN\n",
      "4  NaN  NaN  NaN  NaN   A4   B4   C4   D4\n",
      "5  NaN  NaN  NaN  NaN   A5   B5   C5   D5\n",
      "6  NaN  NaN  NaN  NaN   A6   B6   C6   D6\n",
      "7  NaN  NaN  NaN  NaN   A7   B7   C7   D7\n"
     ]
    }
   ],
   "source": [
    "# Concatenation joins two data frames along the specified axis, with the default being column-wise.\n",
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    "    },\n",
    "    index=[0, 1, 2, 3],\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n",
    "        \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n",
    "        \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n",
    "        \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n",
    "    },\n",
    "    index=[4, 5, 6, 7],\n",
    ")\n",
    "\n",
    "# You can specify the axis to operate on, the default is 0.\n",
    "print(pd.concat([df1, df2], axis=0))\n",
    "print(pd.concat([df1, df2], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "baaec633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    B    C    D    E\n",
      "0   A0   B0   C0   D0  NaN  NaN  NaN  NaN\n",
      "1   A1   B1   C1   D1  NaN  NaN  NaN  NaN\n",
      "2   A2   B2   C2   D2   B2   C2   D2   E2\n",
      "3   A3   B3   C3   D3   B3   C3   D3   E3\n",
      "4  NaN  NaN  NaN  NaN   B4   C4   D4   E4\n",
      "5  NaN  NaN  NaN  NaN   B5   C5   D5   E5\n",
      "    A   B   C   D   B   C   D   E\n",
      "2  A2  B2  C2  D2  B2  C2  D2  E2\n",
      "3  A3  B3  C3  D3  B3  C3  D3  E3\n"
     ]
    }
   ],
   "source": [
    "# if the two dataframes have different columns, you should specify an \"inner\" or \"outer\" join:\n",
    "df3 = pd.DataFrame(\n",
    "    {\n",
    "        \"B\": [\"B2\", \"B3\", \"B4\", \"B5\"],\n",
    "        \"C\": [\"C2\", \"C3\", \"C4\", \"C5\"],\n",
    "        \"D\": [\"D2\", \"D3\", \"D4\", \"D5\"],\n",
    "        \"E\": [\"E2\", \"E3\", \"E4\", \"E5\"],\n",
    "    },\n",
    "    index=[2, 3, 4, 5],\n",
    ")\n",
    "\n",
    "# outer takes the union along the specified axis\n",
    "print(pd.concat([df1, df3], join=\"outer\", axis=1))\n",
    "\n",
    "# inner takes the overlap along the specified axis\n",
    "print(pd.concat([df1, df3], join=\"inner\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc31516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   A   B   C   D\n",
      "0  K0  A0  B0  C0  D0\n",
      "1  K1  A1  B1  C1  D1\n",
      "2  K2  A2  B2  C2  D2\n",
      "3  K3  A3  B3  C3  D3\n"
     ]
    }
   ],
   "source": [
    "# Merging is for SQL-type joining operations (joining based on a key/column value). Again taking the example from the docs,\n",
    "left = pd.DataFrame(\n",
    "    {\n",
    "        \"key\": [\"K0\", \"K1\", \"K2\", \"K3\"],\n",
    "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "right = pd.DataFrame(\n",
    "    {\n",
    "        \"key\": [\"K0\", \"K1\", \"K2\", \"K3\"],\n",
    "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# when merging, specify which column to join on:\n",
    "print(pd.merge(left, right, on=\"key\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3948d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key1 key2   A   B    C    D\n",
      "0   K0   K0  A0  B0   C0   D0\n",
      "1   K0   K1  A1  B1  NaN  NaN\n",
      "2   K1   K0  A2  B2   C1   D1\n",
      "3   K1   K0  A2  B2   C2   D2\n",
      "4   K2   K1  A3  B3  NaN  NaN\n",
      "  key1 key2    A    B   C   D\n",
      "0   K0   K0   A0   B0  C0  D0\n",
      "1   K1   K0   A2   B2  C1  D1\n",
      "2   K1   K0   A2   B2  C2  D2\n",
      "3   K2   K0  NaN  NaN  C3  D3\n",
      "  key1 key2    A    B    C    D\n",
      "0   K0   K0   A0   B0   C0   D0\n",
      "1   K0   K1   A1   B1  NaN  NaN\n",
      "2   K1   K0   A2   B2   C1   D1\n",
      "3   K1   K0   A2   B2   C2   D2\n",
      "4   K2   K0  NaN  NaN   C3   D3\n",
      "5   K2   K1   A3   B3  NaN  NaN\n",
      "  key1 key2   A   B   C   D\n",
      "0   K0   K0  A0  B0  C0  D0\n",
      "1   K1   K0  A2  B2  C1  D1\n",
      "2   K1   K0  A2  B2  C2  D2\n"
     ]
    }
   ],
   "source": [
    "# You can specify the merge type with the \"how\" kwarg:\n",
    "left = pd.DataFrame(\n",
    "   {\n",
    "      \"key1\": [\"K0\", \"K0\", \"K1\", \"K2\"],\n",
    "      \"key2\": [\"K0\", \"K1\", \"K0\", \"K1\"],\n",
    "      \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "      \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "   }\n",
    ")\n",
    "\n",
    "right = pd.DataFrame(\n",
    "   {\n",
    "      \"key1\": [\"K0\", \"K1\", \"K1\", \"K2\"],\n",
    "      \"key2\": [\"K0\", \"K0\", \"K0\", \"K0\"],\n",
    "      \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "      \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    "   }\n",
    ")\n",
    "\n",
    "print(pd.merge(left, right, on=[\"key1\", \"key2\"], how=\"left\"))\n",
    "print(pd.merge(left, right, on=[\"key1\", \"key2\"], how=\"right\"))\n",
    "print(pd.merge(left, right, on=[\"key1\", \"key2\"], how=\"outer\"))\n",
    "print(pd.merge(left, right, on=[\"key1\", \"key2\"], how=\"inner\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf26d954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B    C    D\n",
      "0  A0  B0  NaN  NaN\n",
      "1  A1  B1  NaN  NaN\n",
      "2  A2  B2  NaN  NaN\n",
      "     C   D    A    B\n",
      "K0  C0  D0  NaN  NaN\n",
      "K2  C2  D2  NaN  NaN\n",
      "K3  C3  D3  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "# join is a DataFrame method and is used to join two dataframes based on columns:\n",
    "left = pd.DataFrame(\n",
    "    {\n",
    "\t\t\"A\": [\"A0\", \"A1\", \"A2\"], \n",
    "\t\t\"B\": [\"B0\", \"B1\", \"B2\"]\n",
    "\t}\n",
    ")\n",
    "\n",
    "right = pd.DataFrame(\n",
    "    {\t\n",
    "\t\t\"C\": [\"C0\", \"C2\", \"C3\"], \n",
    "\t\t\"D\": [\"D0\", \"D2\", \"D3\"]\n",
    "\t}, \n",
    "\tindex=[\"K0\", \"K2\", \"K3\"]\n",
    ")\n",
    "\n",
    "print(left.join(right))\n",
    "print(right.join(left))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25afb1",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "As usual, I've barely scratched the surface of what pandas is capable of. If you want to learn more, there's an excellent [user guide](https://pandas.pydata.org/docs/user_guide/index.html) on the pandas website. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hm-env",
   "language": "python",
   "name": "hm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
